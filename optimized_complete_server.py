#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ TALENTSCOPE - SERVEUR OPTIMISÃ‰ COMPLET
Application complÃ¨te avec tous les modules intÃ©grÃ©s
"""

import http.server
import socketserver
import os
import urllib.parse
import json
import subprocess
import threading
import time
from datetime import datetime
import sys

# Configuration
PORT = 8094  # Port optimisÃ©
ML_API_PORT = 8095  # Port pour l'API ML

class OptimizedTalentScopeHandler(http.server.SimpleHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, directory=os.getcwd(), **kwargs)
    
    def do_GET(self):
        parsed_path = urllib.parse.urlparse(self.path)
        path = parsed_path.path
        query = parsed_path.query
        
        print(f"ğŸŒ RequÃªte: {path}")
        
        # Routes principales optimisÃ©es
        if path == '/' or path == '/auth' or path == '/login':
            self.serve_html_file('auth_interface.html')
        elif path == '/dashboard' or path == '/home':
            self.serve_html_file('modern_dashboard.html')
        elif path == '/analysis':
            if 'step=verification' in query:
                self.serve_html_file('analysis_interface_verification_optimized.html')
            else:
                self.serve_html_file('analysis_interface_ml_integrated.html')
        elif path == '/profile':
            self.serve_html_file('profile_management.html')
        elif path == '/config':
            self.serve_html_file('modern_dashboard.html')
        elif path == '/users' or path == '/user-management':
            self.serve_html_file('user_management.html')
        elif path == '/diagnostic':
            self.serve_html_file('diagnostic_complet.html')
        elif path == '/test':
            self.serve_html_file('test_user_data.html')
        elif path == '/migrate':
            self.serve_html_file('migrate_accounts.html')
        else:
            # Servir les fichiers statiques
            self.serve_static_file(path)
    
    def do_POST(self):
        """Gestion des requÃªtes POST pour l'API"""
        content_length = int(self.headers['Content-Length'])
        post_data = self.rfile.read(content_length)
        
        try:
            data = json.loads(post_data.decode('utf-8'))
            print(f"ğŸ“¨ POST reÃ§u: {data}")
            
            # Rediriger vers l'API ML si nÃ©cessaire
            if self.path.startswith('/api/'):
                self.handle_ml_api_request(data)
            else:
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                response = {"status": "success", "message": "RequÃªte traitÃ©e"}
                self.wfile.write(json.dumps(response).encode())
                
        except Exception as e:
            print(f"âŒ Erreur POST: {e}")
            self.send_error(500, f"Erreur serveur: {str(e)}")
    
    def handle_ml_api_request(self, data):
        """Rediriger les requÃªtes ML vers l'API dÃ©diÃ©e"""
        try:
            import requests
            ml_url = f"http://localhost:{ML_API_PORT}/analyze"
            response = requests.post(ml_url, json=data, timeout=30)
            
            self.send_response(response.status_code)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(response.content)
            
        except Exception as e:
            print(f"âŒ Erreur API ML: {e}")
            self.send_error(500, f"Erreur API ML: {str(e)}")
    
    def serve_html_file(self, filename):
        """Servir un fichier HTML avec optimisations"""
        try:
            if os.path.exists(filename):
                with open(filename, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Optimisations automatiques
                content = self.optimize_html_content(content)
                
                self.send_response(200)
                self.send_header('Content-type', 'text/html; charset=utf-8')
                self.send_header('Cache-Control', 'no-cache')
                self.end_headers()
                self.wfile.write(content.encode('utf-8'))
                
                print(f"âœ… HTML servi: {filename}")
            else:
                self.send_error(404, f"Fichier non trouvÃ©: {filename}")
                print(f"âŒ Fichier non trouvÃ©: {filename}")
                
        except Exception as e:
            print(f"âŒ Erreur serveur HTML: {e}")
            self.send_error(500, f"Erreur serveur: {str(e)}")
    
    def serve_static_file(self, path):
        """Servir les fichiers statiques avec optimisations"""
        try:
            filename = path.lstrip('/')
            
            # Mapper les extensions
            content_types = {
                '.css': 'text/css',
                '.js': 'application/javascript',
                '.png': 'image/png',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.gif': 'image/gif',
                '.svg': 'image/svg+xml',
                '.ico': 'image/x-icon',
                '.json': 'application/json',
                '.pdf': 'application/pdf'
            }
            
            if os.path.exists(filename):
                ext = os.path.splitext(filename)[1].lower()
                content_type = content_types.get(ext, 'application/octet-stream')
                
                self.send_response(200)
                self.send_header('Content-type', content_type)
                self.send_header('Cache-Control', 'public, max-age=3600')
                self.end_headers()
                
                with open(filename, 'rb') as f:
                    self.wfile.write(f.read())
                
                print(f"ğŸ“ Fichier servi: {filename}")
            else:
                self.send_error(404, f"Fichier non trouvÃ©: {filename}")
                print(f"âŒ Fichier non trouvÃ©: {filename}")
                
        except Exception as e:
            print(f"âŒ Erreur serveur fichier: {e}")
            self.send_error(500, f"Erreur serveur: {str(e)}")
    
    def optimize_html_content(self, content):
        """Optimiser le contenu HTML"""
        # Ajouter des mÃ©tadonnÃ©es d'optimisation
        if '<head>' in content:
            optimization_meta = '''
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="TalentScope - Application de matching CV">
    <meta name="author" content="MinistÃ¨re de l'Ã‰conomie et des Finances">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    '''
            content = content.replace('<head>', f'<head>{optimization_meta}')
        
        return content
    
    def log_message(self, format, *args):
        """Log personnalisÃ© avec timestamp"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"[{timestamp}] {format % args}")

def start_ml_api():
    """DÃ©marrer l'API ML en arriÃ¨re-plan"""
    try:
        print("ğŸ¤– DÃ©marrage de l'API ML...")
        # DÃ©marrer l'API ML sur un port diffÃ©rent
        ml_process = subprocess.Popen([
            sys.executable, 'talent_scope_ml_api.py',
            '--port', str(ML_API_PORT),
            '--host', '127.0.0.1'
        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        time.sleep(2)  # Attendre que l'API dÃ©marre
        print(f"âœ… API ML dÃ©marrÃ©e sur le port {ML_API_PORT}")
        return ml_process
        
    except Exception as e:
        print(f"âŒ Erreur dÃ©marrage API ML: {e}")
        return None

def check_dependencies():
    """VÃ©rifier les dÃ©pendances"""
    print("ğŸ” VÃ©rification des dÃ©pendances...")
    
    required_files = [
        'auth_interface.html',
        'modern_dashboard.html',
        'profile_management.html',
        'analysis_interface_optimized.html',
        'user_database.js',
        'themes.css',
        'direct-translation.js',
        'talent_scope_ml_api.py'
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ Fichiers manquants: {missing_files}")
        return False
    
    print("âœ… Toutes les dÃ©pendances sont prÃ©sentes")
    return True

def main():
    """Fonction principale"""
    print("ğŸš€ TALENTSCOPE - SERVEUR OPTIMISÃ‰ COMPLET")
    print("=" * 50)
    
    # VÃ©rifier les dÃ©pendances
    if not check_dependencies():
        print("âŒ DÃ©pendances manquantes. ArrÃªt du serveur.")
        return
    
    # DÃ©marrer l'API ML
    ml_process = start_ml_api()
    
    try:
        # CrÃ©er le serveur
        with socketserver.TCPServer(("", PORT), OptimizedTalentScopeHandler) as httpd:
            print(f"âœ… Serveur principal dÃ©marrÃ© sur http://localhost:{PORT}")
            print(f"ğŸ¤– API ML sur http://localhost:{ML_API_PORT}")
            print("=" * 50)
            print("ğŸ¯ Modules disponibles:")
            print("   â€¢ ğŸ” Authentification: /auth")
            print("   â€¢ ğŸ“Š Dashboard: /dashboard")
            print("   â€¢ ğŸ‘¤ Profil: /profile")
            print("   â€¢ ğŸ” Analyse: /analysis")
            print("   â€¢ âš™ï¸ Configuration: /config")
            print("   â€¢ ğŸ‘¥ Gestion utilisateurs: /users")
            print("   â€¢ ğŸ§ª Diagnostic: /diagnostic")
            print("=" * 50)
            print("ğŸ”„ Le serveur est en cours d'exÃ©cution...")
            print("ğŸ“ Appuyez sur Ctrl+C pour arrÃªter")
            print("=" * 50)
            
            # DÃ©marrer le serveur
            httpd.serve_forever()
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ArrÃªt du serveur...")
    except OSError as e:
        if e.errno == 10048:  # Port dÃ©jÃ  utilisÃ©
            print(f"âŒ Port {PORT} dÃ©jÃ  utilisÃ©. Essayez un autre port.")
        else:
            print(f"âŒ Erreur serveur: {e}")
    finally:
        # ArrÃªter l'API ML
        if ml_process:
            print("ğŸ›‘ ArrÃªt de l'API ML...")
            ml_process.terminate()
            ml_process.wait()

if __name__ == "__main__":
    main()


